{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602462e6",
   "metadata": {},
   "source": [
    "# Proof of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116cdcf4",
   "metadata": {},
   "source": [
    "The objective of this notebook is to develop a proof of concept:\n",
    "- Load tweets from twarc-extracted `jsonl` files.\n",
    "- Parse tweets and use `Vader` to add sentiment.\n",
    "- Show a brief example analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121bb98",
   "metadata": {},
   "source": [
    "## 0. Load Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b42634a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\pyrol\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Any, Callable, Union\n",
    "from functools import reduce\n",
    "from operator import getitem\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df18a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW_DATA_DIR = \"/Users/pyrol/code/gym-vendor-analysis/data/\"\n",
    "RAW_DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e58bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_DICT_KEY_MAPPING = [\n",
    "    ((\"url\",), \"url\",),\n",
    "    ((\"content\",), \"content\",),\n",
    "    ((\"id\",), \"tweet_id\",),\n",
    "    ((\"user\", \"id\",), \"user_id\",),\n",
    "    ((\"user\", \"username\",), \"user_name\",),\n",
    "    ((\"date\",), \"datetime\",),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "685bacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dictionary_get(d: Dict, key: Tuple):\n",
    "    return reduce(getitem, key, d)\n",
    "\n",
    "\n",
    "def parse_and_reduce_tweet(tweet: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parses a tweet (represented as a dictionary), reducing the tweet to the schema defined\n",
    "    in `keys_set`\n",
    "    \"\"\"\n",
    "    new_dict = {new_name: nested_dictionary_get(d=tweet, key=nested_key)\n",
    "                for nested_key, new_name in TWEET_DICT_KEY_MAPPING}\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc3c04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_twarc_file_to_list_of_tweets(filename: str,\n",
    "                                                include_filename_in_result=True,\n",
    "                                                raw_data_dir: str = RAW_DATA_DIR\n",
    "                                               ) -> List:\n",
    "    path = os.path.join(raw_data_dir, f\"{filename}.jsonl\")\n",
    "    print(f\"Loading data from {path}.\")\n",
    "    with open(path, 'r') as f:\n",
    "        if include_filename_in_result:\n",
    "            tweet_list = [{**parse_and_reduce_tweet(json.loads(line)), **{\"vendor\": filename}} for line in f]\n",
    "        else:\n",
    "            tweet_list = [parse_and_reduce_tweet(json.loads(line)) for line in f]\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82d71e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twarc_json_file_to_dataframe(filename: str) -> pd.DataFrame:\n",
    "    tweets_list = load_and_parse_twarc_file_to_list_of_tweets(filename=filename)\n",
    "    tweet_df = pd.DataFrame.from_records(tweets_list)\n",
    "    return tweet_df\n",
    "\n",
    "\n",
    "def load_twarc_json_files_to_dataframe(filenames: List[str]) -> pd.DataFrame:\n",
    "    tweet_dfs = [load_twarc_json_file_to_dataframe(filename) for filename in filenames]\n",
    "    tweet_df = pd.concat(tweet_dfs)\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a587616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets_df(df, path):\n",
    "    print(f\"Saving data to {path}.\")\n",
    "    df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7446955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets_df(path):\n",
    "    print(f\"Loading data from {path}.\")\n",
    "    return pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb67d8",
   "metadata": {},
   "source": [
    "## 1. Load Tweets Data, Enrich with Sentiment, and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd781b",
   "metadata": {},
   "source": [
    "#### Load tweets to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a090fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_vendors = [\n",
    "    \"Arsenal_Strngth\",\n",
    "    \"BeTitanFit\",\n",
    "    \"BodySolidFit\",\n",
    "    \"BodycraftFit\",\n",
    "    \"CAPBarbell84\",\n",
    "    \"HOISTFitness\",\n",
    "    \"HammerStrength\",\n",
    "    \"LifeFitness\",\n",
    "    \"PRxPerformance\",\n",
    "    \"Powertec\",\n",
    "    \"RepFitnessEquip\",\n",
    "    \"RogueFitness\",\n",
    "    \"Sorinex\",\n",
    "    \"TorqueFitness\",\n",
    "    \"bellsofsteel\",\n",
    "    \"concept2\",\n",
    "    \"cybex\",\n",
    "    \"elitefts\",\n",
    "    \"force_usa\",\n",
    "    \"onepeloton\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8524ddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/Arsenal_Strngth.jsonl.\n",
      "Loading data from ../data/BeTitanFit.jsonl.\n",
      "Loading data from ../data/BodySolidFit.jsonl.\n",
      "Loading data from ../data/BodycraftFit.jsonl.\n",
      "Loading data from ../data/CAPBarbell84.jsonl.\n",
      "Loading data from ../data/HOISTFitness.jsonl.\n",
      "Loading data from ../data/HammerStrength.jsonl.\n",
      "Loading data from ../data/LifeFitness.jsonl.\n",
      "Loading data from ../data/PRxPerformance.jsonl.\n",
      "Loading data from ../data/Powertec.jsonl.\n",
      "Loading data from ../data/RepFitnessEquip.jsonl.\n",
      "Loading data from ../data/RogueFitness.jsonl.\n",
      "Loading data from ../data/Sorinex.jsonl.\n",
      "Loading data from ../data/TorqueFitness.jsonl.\n",
      "Loading data from ../data/bellsofsteel.jsonl.\n",
      "Loading data from ../data/concept2.jsonl.\n",
      "Loading data from ../data/cybex.jsonl.\n",
      "Loading data from ../data/elitefts.jsonl.\n",
      "Loading data from ../data/force_usa.jsonl.\n",
      "Loading data from ../data/onepeloton.jsonl.\n"
     ]
    }
   ],
   "source": [
    "# tweet_df = load_twarc_json_file_to_dataframe(path=paths[0], parse_tweet_fxn=parse_and_reduce_tweet)\n",
    "tweet_df = load_twarc_json_files_to_dataframe(filenames=gym_vendors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747fe6c",
   "metadata": {},
   "source": [
    "#### Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13e4b221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://twitter.com/Ayoobi77/status/1567340537333837824</td>\n",
       "      <td>https://twitter.com/Arsenal_Strngth/status/1567145753360977922</td>\n",
       "      <td>https://twitter.com/Arsenal_Strngth/status/1567144502334308354</td>\n",
       "      <td>https://twitter.com/Ayoobi77/status/1566312069196124166</td>\n",
       "      <td>https://twitter.com/Ayoobi77/status/1566311005038297089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>@Arsenal_Strngth The true face of sports engineering üôÇ\\nArsenal Strength</td>\n",
       "      <td>Shipping soon: black on black Reloaded Iso Lat Pull down. https://t.co/GgnZl99ZhI</td>\n",
       "      <td>@Ayoobi77 @Collin_Abel10 @EaglevilleFB @CoachFWalker Thank you! ‚öîÔ∏è</td>\n",
       "      <td>@Collin_Abel10 @Arsenal_Strngth @EaglevilleFB @CoachFWalker The best machine</td>\n",
       "      <td>@Arsenal_Strngth Excellent products from Arsenal Strength üëçüëçüëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <td>1567340537333837824</td>\n",
       "      <td>1567145753360977922</td>\n",
       "      <td>1567144502334308354</td>\n",
       "      <td>1566312069196124166</td>\n",
       "      <td>1566311005038297089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>787689201231888384</td>\n",
       "      <td>2942005261</td>\n",
       "      <td>2942005261</td>\n",
       "      <td>787689201231888384</td>\n",
       "      <td>787689201231888384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_name</th>\n",
       "      <td>Ayoobi77</td>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "      <td>Ayoobi77</td>\n",
       "      <td>Ayoobi77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>2022-09-07T02:34:38+00:00</td>\n",
       "      <td>2022-09-06T13:40:38+00:00</td>\n",
       "      <td>2022-09-06T13:35:40+00:00</td>\n",
       "      <td>2022-09-04T06:27:52+00:00</td>\n",
       "      <td>2022-09-04T06:23:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "      <td>Arsenal_Strngth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  0  \\\n",
       "url                         https://twitter.com/Ayoobi77/status/1567340537333837824   \n",
       "content    @Arsenal_Strngth The true face of sports engineering üôÇ\\nArsenal Strength   \n",
       "tweet_id                                                        1567340537333837824   \n",
       "user_id                                                          787689201231888384   \n",
       "user_name                                                                  Ayoobi77   \n",
       "datetime                                                  2022-09-07T02:34:38+00:00   \n",
       "vendor                                                              Arsenal_Strngth   \n",
       "\n",
       "                                                                                           1  \\\n",
       "url                           https://twitter.com/Arsenal_Strngth/status/1567145753360977922   \n",
       "content    Shipping soon: black on black Reloaded Iso Lat Pull down. https://t.co/GgnZl99ZhI   \n",
       "tweet_id                                                                 1567145753360977922   \n",
       "user_id                                                                           2942005261   \n",
       "user_name                                                                    Arsenal_Strngth   \n",
       "datetime                                                           2022-09-06T13:40:38+00:00   \n",
       "vendor                                                                       Arsenal_Strngth   \n",
       "\n",
       "                                                                            2  \\\n",
       "url            https://twitter.com/Arsenal_Strngth/status/1567144502334308354   \n",
       "content    @Ayoobi77 @Collin_Abel10 @EaglevilleFB @CoachFWalker Thank you! ‚öîÔ∏è   \n",
       "tweet_id                                                  1567144502334308354   \n",
       "user_id                                                            2942005261   \n",
       "user_name                                                     Arsenal_Strngth   \n",
       "datetime                                            2022-09-06T13:35:40+00:00   \n",
       "vendor                                                        Arsenal_Strngth   \n",
       "\n",
       "                                                                                      3  \\\n",
       "url                             https://twitter.com/Ayoobi77/status/1566312069196124166   \n",
       "content    @Collin_Abel10 @Arsenal_Strngth @EaglevilleFB @CoachFWalker The best machine   \n",
       "tweet_id                                                            1566312069196124166   \n",
       "user_id                                                              787689201231888384   \n",
       "user_name                                                                      Ayoobi77   \n",
       "datetime                                                      2022-09-04T06:27:52+00:00   \n",
       "vendor                                                                  Arsenal_Strngth   \n",
       "\n",
       "                                                                       4  \n",
       "url              https://twitter.com/Ayoobi77/status/1566311005038297089  \n",
       "content    @Arsenal_Strngth Excellent products from Arsenal Strength üëçüëçüëç  \n",
       "tweet_id                                             1566311005038297089  \n",
       "user_id                                               787689201231888384  \n",
       "user_name                                                       Ayoobi77  \n",
       "datetime                                       2022-09-04T06:23:38+00:00  \n",
       "vendor                                                   Arsenal_Strngth  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c44f8034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832517, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1096a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url          0.0\n",
       "content      0.0\n",
       "tweet_id     0.0\n",
       "user_id      0.0\n",
       "user_name    0.0\n",
       "datetime     0.0\n",
       "vendor       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e508343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url          object\n",
       "content      object\n",
       "tweet_id      int64\n",
       "user_id       int64\n",
       "user_name    object\n",
       "datetime     object\n",
       "vendor       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636acd5",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b06a0a",
   "metadata": {},
   "source": [
    "##### datetime field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0ddeab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df[\"pd_datetime\"] = pd.to_datetime(tweet_df[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edf83e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                         object\n",
       "content                     object\n",
       "tweet_id                     int64\n",
       "user_id                      int64\n",
       "user_name                   object\n",
       "datetime                    object\n",
       "vendor                      object\n",
       "pd_datetime    datetime64[ns, UTC]\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76aa5a",
   "metadata": {},
   "source": [
    "#### Create Sample dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "037518cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_sample = tweet_df.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0688582",
   "metadata": {},
   "source": [
    "#### Enrich Tweets with sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc987c9",
   "metadata": {},
   "source": [
    "From [Vader docs](https://vadersentiment.readthedocs.io/en/latest/pages/about_the_scoring.html):  \n",
    "> The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a ‚Äònormalized, weighted composite score‚Äô is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43a2031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c4c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                     | 213752/832517 [05:55<04:42, 2187.42it/s]"
     ]
    }
   ],
   "source": [
    "tweet_df[\"sentiment\"] = tweet_df[\"content\"].progress_apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721dee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ba929",
   "metadata": {},
   "source": [
    "#### Validate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df[[\"content\", \"sentiment\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507c2e9",
   "metadata": {},
   "source": [
    "Sentiment seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b63f44",
   "metadata": {},
   "source": [
    "#### Export tweets df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933005fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/tweet_df.parquet\"\n",
    "save_tweets_df(tweet_df, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44441ce9",
   "metadata": {},
   "source": [
    "## 2. Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/tweet_df.parquet\"\n",
    "tweet_df = load_tweets_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15, 15))\n",
    "for plt_index, val, aggfunc, chart_name, chart_ylabel in [\n",
    "    (0, \"tweet_id\", \"count\", \"Total Tweet Volume per Month\", \"Count Tweets\"),\n",
    "    (1, \"sentiment\", \"sum\", \"Total Tweet Sentiment per Month\", \"Sum Tweet Sentiments\")]:\n",
    "    result = (tweet_df\n",
    "              .assign(**{\"date\": tweet_df.pd_datetime.dt.date})\n",
    "              .pivot_table(index=\"date\",\n",
    "                           columns=\"vendor\",\n",
    "                           values=val,\n",
    "                           aggfunc=aggfunc)\n",
    "              .fillna(0))\n",
    "    result = result.set_index(pd.to_datetime(result.index)).resample('M').sum()\n",
    "    result.plot(ax=axs[plt_index])\n",
    "    axs[plt_index].set_title(chart_name)\n",
    "    axs[plt_index].set_ylabel(chart_ylabel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef45b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
